<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
   <html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <!-- Favicon -->
  <link href="../images/vl_blue.ico" type="image/x-icon" rel="icon"></link>
  <link href="../images/vl_blue.ico" type="image/x-icon" rel="shortcut icon"></link>

  <!-- Page title -->
  <title>VLFeat - Applications</title>

  <!-- Stylesheets -->
  <link href="../vlfeat.css" type="text/css" rel="stylesheet"></link>
  <link href="../pygmentize.css" type="text/css" rel="stylesheet"></link>
  <style xml:space="preserve">
    /* fixes a conflict between Pygmentize and MathJax */
    .MathJax .mo, .MathJax .mi {color: inherit ! important}
  </style>
  <style rel="stylesheet" type="text/css" >
#content table.checker {
    border-collapse: collapse ;
    margin-left: auto ;
    margin-right: auto ;
}
#content table.checker td {
    background-color: #f6f6f6 ;
    border: 1px solid #DDD ;
    padding: 0.5em ;
}
</style>


  <!-- Scripts-->
  

  <!-- MathJax -->
  <script xml:space="preserve" type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      processEscapes: true,
    },
    TeX: {
      Macros: {
        balpha: '\\boldsymbol{\\alpha}',
        bc: '\\mathbf{c}',
        be: '\\mathbf{e}',
        bg: '\\mathbf{g}',
        bq: '\\mathbf{q}',
        bu: '\\mathbf{u}',
        bv: '\\mathbf{v}',
        bw: '\\mathbf{w}',
        bx: '\\mathbf{x}',
        by: '\\mathbf{y}',
        bz: '\\mathbf{z}',
        bsigma: '\\mathbf{\\sigma}',
        sign: '\\operatorname{sign}',
        diag: '\\operatorname{diag}',
        real: '\\mathbb{R}',
      },
      equationNumbers: { autoNumber: 'AMS' }
      }
    });
  </script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" xml:space="preserve" type="text/javascript"></script>

  <!-- Google Custom Search -->
  <script xml:space="preserve">
    (function() {
    var cx = '003215582122030917471:oq23albfeam';
    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
    '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
    })();
  </script>

  <!-- Google Analytics -->
  <script xml:space="preserve" type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-4936091-2']);
    _gaq.push(['_trackPageview']);
    (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
 </head>

 <!-- Body Start -->
 <body>
  <div id="header-section">
    <div id="header">
      <!-- Google CSE Search Box -->
      <div id="google" class="gcse-searchbox-only" data-resultsUrl="http://www.vlfeat.org/search.html"></div>
      <h1 id="id-13"><a shape="rect" href="../index.html" class="plain"><span id="vlfeat">VLFeat</span><span id="dotorg">.org</span></a></h1>
    </div>
  </div>
  <div id="headbanner-section">
    <div id="headbanner">
      Applications
    </div>
  </div>
  <div id="content-section">
    <div id="content-wrapper">
      <div id="sidebar"> <!-- Navigation Start -->
        <ul>
<li><a href="../index.html">Home</a>
</li>
<li><a href="../download.html">Download</a>
</li>
<li><a href="../overview/tut.html">Tutorials</a>
</li>
<li><a href="apps.html" class='active' >Applications</a>
</li>
<li><a href="../doc.html">Documentation</a>
</li>
</ul>

      </div> <!-- sidebar -->
      <div id="content">
        
    



<p>This page lists a number of sample VLFeat applications. Their code
  can be found in the <code/>VLROOT/apps/</code> subdirectory.</p>

<h1 id="apps.caltech-101">Basic recognition</h1>



<img src="../images/caltech-collage.jpg" alt="Caltech-101 Collage"></img>

<p>This sample application uses VLFeat to train an test an image
classifier on the Caltech-101 data. The classifier achieves 65%
average accuracy by using a single feature and 15 training images per
class. It uses:</p>
<ul>
<li>PHOW features (dense multi-scale SIFT descriptors)</li>
<li>Elkan k-means for fast visual word dictionary
construction</li>
<li>Spatial histograms as image descriptors</li>
<li>A homogeneous kernel map to transform a Chi2 support vector
machine (SVM) into a linear one</li>
<li>SVM classifiers</li>
</ul>

<p>The program is fully contained in
a <a shape="rect" href="caltech-101-code.html">single MATLAB M-file</a>,
and can also be simply adapted to use your own data (change
conf.calDir).</p>

<h1 id="apps.recognition">Advanced encodings for recognition</h1>



<p>This example application extends the Caltech-101 demo above in many
ways: it supports multiple encoding methods, including BoVW, VLAD, and
Fisher Vectors, tweaked image featuers, and multiple benchmark
datasets. The code is located int <code/>apps/recognition</code>. Start
from the <a shape="rect" href="experiments.html">main
file</a>.</p>

<p>The following tables report results on a few standard benchmark
datasets (PASCAL VOC 2007 classification challenge, Caltech 101 30
training images, MIT Scene 67, and Flickr Material Dataset) for a
number of different encodings:</p>

<table class="checker">
<tr><th colspan="1" rowspan="1">method</th><th colspan="1" rowspan="1">VOC07</th><th colspan="1" rowspan="1">Caltech 101</th><th colspan="1" rowspan="1">Scene 67</th><th colspan="1" rowspan="1">FMD</th></tr>
<tr><td colspan="1" rowspan="1">FV</td><td colspan="1" rowspan="1">59.12% <span style="font-size:8px;">mAP</span></td><td colspan="1" rowspan="1">73.02% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">58.25% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">59.60% <span style="font-size:8px;">Acc</span></td></tr>
<tr><td colspan="1" rowspan="1">FV + aug.</td><td colspan="1" rowspan="1">60.25% <span style="font-size:8px;">mAP</span></td><td colspan="1" rowspan="1">75.61% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">57.57% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">60.80% <span style="font-size:8px;">Acc</span></td></tr>
<tr><td colspan="1" rowspan="1">FV + s.p.</td><td colspan="1" rowspan="1">62.23% <span style="font-size:8px;">mAP</span></td><td colspan="1" rowspan="1">77.63% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">61.83% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">60.80% <span style="font-size:8px;">Acc</span></td></tr>
<tr><td colspan="1" rowspan="1">VLAD + aug.</td><td colspan="1" rowspan="1">54.66% <span style="font-size:8px;">mAP</span></td><td colspan="1" rowspan="1">78.68% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">53.29% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">49.40% <span style="font-size:8px;">Acc</span></td></tr>
<tr><td colspan="1" rowspan="1">BOVW + aug.</td><td colspan="1" rowspan="1">49.87% <span style="font-size:8px;">mAP</span></td><td colspan="1" rowspan="1">75.98% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">50.22% <span style="font-size:8px;">Acc</span></td><td colspan="1" rowspan="1">46.00% <span style="font-size:8px;">Acc</span></td></tr>
</table>

<p>The baseline feature is SIFT (<code/><a href=../matlab/vl_dsift.html>vl_dsift</a></code>) computed at
seven scales with a factor $\sqrt{2}$ between successive scales, bins
8 pixel wide, and comptued with a step of 4 pixels. All experiments
but the Caltech-101 ones start by doubling the resolution of the input
image. The details of the encodings are as follows:</p>

<ul>
<li>Bag-of-visual-words uses 4096 vector quantized visual words
histogram square rooting, followed by $L^2$ normalization (Hellinger's
kernel).</li>
<li><a shape="rect" href="..//api/vlad.html">VLAD</a> uses 256 vector quantized visual
words, signed square-rooting, component wise $L^2$ normalization, and
global $L^2$ normalization (see <code/><a href=../matlab/vl_vlad.html>vl_vlad</a></code>).</li>
<li><a shape="rect" href="..//api/fisher.html">Fisher vectors</a> uses a 256 visual words
GMM and the improved formulation (signed square-rooting followed by
$L^2$ normlization, see <code/><a href=../matlab/vl_fisher.html>vl_fisher</a></code>).</li>
<li>Learning uses a <a shape="rect" href="..//api/svm.html">linear SVM</a>
(see <code/><a href=../matlab/vl_svmtrain.html>vl_svmtrain</a></code>). The parameter $C$ is set to 10 for all
dataset except PASCAL VOC, for which it is set to 1.</li>
<li>Experiments labelled with &ldquo;aug.&rdquo; encode spatial
information by appending the feature coordinates to the descriptor;
the ones labelled with &ldquo;s.p.&rdquo; use a spatial pyramid with
1x1 and 3x1 subdivisions.</li>
</ul>

<h1 id="apps.sift-mosaic">SIFT mosaic</h1>



<img src="../images/sift-mosaic.jpg" alt="SIFT mosaic"></img>

<p>This sample application uses VLFeat to extract SIFT features form a
pair of images and match them. It then filters the matches based on
RANSAC and produces a mosaic. Read
the <a shape="rect" href="sift-mosaic-code.html">code</a>.</p>


  
      </div>
      <div class="clear">&nbsp;</div>
    </div>
  </div> <!-- content-section -->
  <div id="footer-section">
    <div id="footer">
      &copy; 2007-13 The authors of VLFeat
    </div> <!-- footer -->
  </div> <!-- footer section -->
 </body>
 <!-- Body ends -->
</html>
 